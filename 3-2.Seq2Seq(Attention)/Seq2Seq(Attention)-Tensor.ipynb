{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq(Attention)-Tensor.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"OhzGzhE2iMO_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":432},"outputId":"ae564ad7-ccb7-462e-f313-c200407fe917","executionInfo":{"status":"ok","timestamp":1550476789980,"user_tz":-540,"elapsed":11608,"user":{"displayName":"Minho Ryu","photoUrl":"https://lh5.googleusercontent.com/-DfVUFWgMLnc/AAAAAAAAAAI/AAAAAAAAApE/jyfqVt9TIvM/s64/photo.jpg","userId":"01830135931220651986"}}},"cell_type":"code","source":["# code by Minho Ryu @bzantium\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","tf.reset_default_graph()\n","# S: Symbol that shows starting of decoding input\n","# E: Symbol that shows starting of decoding output\n","# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n","sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n","\n","word_list = \" \".join(sentences).split()\n","word_list = list(set(word_list))\n","word_dict = {w: i for i, w in enumerate(word_list)}\n","number_dict = {i: w for i, w in enumerate(word_list)}\n","n_class = len(word_dict)  # vocab list\n","\n","# Parameter\n","n_step = 5  # maxium number of words in one sentence(=number of time steps)\n","n_hidden = 128\n","\n","def make_batch(sentences):\n","    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n","    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n","    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n","    return input_batch, output_batch, target_batch\n","\n","# Model\n","class seq2seq_attn(object):\n","    def __init__(self, sess, n_step, n_hidden, n_class):\n","        self.sess = sess\n","        self.n_step = n_step\n","        self.n_hidden = n_hidden\n","        self.n_class = n_class\n","        self._build_model()\n","    \n","    def _build_model(self):\n","        with tf.variable_scope('placeholder'):\n","            self.enc_inputs = tf.placeholder(tf.float32, [None, None, self.n_class])  # [batch_size, n_step, n_class]\n","            self.dec_inputs = tf.placeholder(tf.float32, [None, None, self.n_class])  # [batch_size, n_step, n_class]\n","            self.targets = tf.placeholder(tf.int64, [1, self.n_step])  # [batch_size, n_step], not one-hot\n","        \n","        # Linear for attention\n","        attn = tf.Variable(tf.random_normal([n_hidden, n_hidden]))\n","        out = tf.Variable(tf.random_normal([n_hidden * 2, n_class]))\n","        \n","        def get_att_score(dec_output, enc_output):  # enc_output [n_step, n_hidden]\n","            score = tf.squeeze(tf.matmul(enc_output, attn), 0)  # score : [n_hidden]\n","            dec_output = tf.squeeze(dec_output, [0, 1])  # dec_output : [n_hidden]\n","            return tf.tensordot(dec_output, score, 1)  # inner product make scalar value\n","\n","        def get_att_weight(dec_output, enc_outputs):\n","            attn_scores = []  # list of attention scalar : [n_step]\n","            enc_outputs = tf.transpose(enc_outputs, [1, 0, 2])  # enc_outputs : [n_step, batch_size, n_hidden]\n","            for i in range(n_step):\n","                attn_scores.append(get_att_score(dec_output, enc_outputs[i]))\n","\n","            # Normalize scores to weights in range 0 to 1\n","            return tf.reshape(tf.nn.softmax(attn_scores), [1, 1, -1])  # [1, 1, n_step]\n","\n","                \n","        model = []\n","        Attention = []\n","        with tf.variable_scope('encode'):\n","            enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n","            enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n","            # enc_outputs : [batch_size(=1), n_step(=decoder_step), n_hidden(=128)]\n","            # enc_hidden : [batch_size(=1), n_hidden(=128)]\n","            enc_outputs, enc_hidden = tf.nn.dynamic_rnn(enc_cell, self.enc_inputs, dtype=tf.float32)\n","\n","        with tf.variable_scope('decode'):\n","            dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n","            dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n","\n","            inputs = tf.transpose(self.dec_inputs, [1, 0, 2])\n","            hidden = enc_hidden\n","            for i in range(n_step):\n","                # time_major True mean inputs shape: [max_time, batch_size, ...]\n","                dec_output, hidden = tf.nn.dynamic_rnn(dec_cell, tf.expand_dims(inputs[i], 1),\n","                                                       initial_state=hidden, dtype=tf.float32, time_major=True)\n","                attn_weights = get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n","                Attention.append(tf.squeeze(attn_weights))\n","\n","                # matrix-matrix product of matrices [1, 1, n_step] x [1, n_step, n_hidden] = [1, 1, n_hidden]\n","                context = tf.matmul(attn_weights, enc_outputs)\n","                dec_output = tf.squeeze(dec_output, 0)  # [1, n_step]\n","                context = tf.squeeze(context, 1)  # [1, n_hidden]\n","\n","                model.append(tf.matmul(tf.concat((dec_output, context), 1), out))  # [n_step, batch_size(=1), n_class]\n","\n","        self.trained_attn = tf.stack([Attention[0], Attention[1], Attention[2], Attention[3], Attention[4]], 0)  # to show attention matrix\n","        logits = tf.transpose(model, [1, 0, 2])  # model : [n_step, n_class]\n","        self.cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=self.targets))\n","        self.optimizer = tf.train.AdamOptimizer(0.001).minimize(self.cost)\n","\n","        self.prediction = tf.argmax(logits, 2)\n","\n","        sess.run(tf.global_variables_initializer())\n","    \n","    def train(self, enc_input, dec_input, targets):\n","        return self.sess.run([self.cost, self.optimizer], feed_dict={self.enc_inputs: enc_input, self.dec_inputs: dec_input, self.targets: targets})\n","     \n","    def predict(self, enc_input, dec_input):\n","        return self.sess.run(self.prediction, feed_dict={self.enc_inputs: enc_input, self.dec_inputs: dec_input})\n","      \n","    def get_attn(self, enc_input, dec_input):\n","        return self.sess.run(self.trained_attn, feed_dict={self.enc_inputs: enc_input, self.dec_inputs: dec_input})\n","        \n","\n","# Training and Test\n","with tf.Session() as sess:\n","    model = seq2seq_attn(sess, n_step, n_hidden, n_class)\n","    input_batch, output_batch, target_batch = make_batch(sentences)\n","    for epoch in range(500):\n","        loss, _ = model.train(input_batch, output_batch, target_batch)\n","\n","        if (epoch + 1) % 100 == 0:\n","            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n","\n","    predict_batch = [np.eye(n_class)[[word_dict[n] for n in 'P P P P P'.split()]]]\n","    result = model.predict(input_batch,predict_batch)\n","    print(sentences[0].split(), '->', [number_dict[n] for n in result[0]])\n","    \n","    # Show Attention\n","    attention = model.get_attn(input_batch, output_batch)\n","    fig = plt.figure(figsize=(5, 5))\n","    ax = fig.add_subplot(1, 1, 1)\n","    ax.matshow(attention, cmap='viridis')\n","    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n","    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n","    plt.show()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch: 0100 cost = 0.000036\n","Epoch: 0200 cost = 0.000096\n","Epoch: 0300 cost = 0.000235\n","Epoch: 0400 cost = 0.000000\n","Epoch: 0500 cost = 0.000000\n","['ich', 'mochte', 'ein', 'bier', 'P'] -> ['i', 'want', 'a', 'beer', 'E']\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUIAAAEzCAYAAABE0wr4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFdNJREFUeJzt3Wl0VfW9h/FvQiargFUGDRBurBj1\nmpAEQqBMNgGhkXKDFGm8QQaFFCwVcIHAsmIti2FdHAqRLCy2pGjRIogLrNAgTgUKRGCZAAaJwQyM\nMojBQEjOvi+op6SAJEj2xvyez6vkTL//P+f4sPc5yyTAcRxHAGBYoNcLAACvEUIA5hFCAOYRQgDm\nEUIA5hFCAOaZDmFZWZmio6O1Z8+eb71dUlKSXn75ZZdW5b558+bpvvvu83oZ38mKFSvUo0cPr5dR\nJ6WlpYqKitLu3bvPu+77uJ/vsyCvF+ClVq1aKS8vz+tlXPVOnDiht99+W4MHD/Z6KReVmpqq1NRU\nr5dxxTS0/ZwrKSlJBw8eVGDg2eOwkJAQtWvXTmPHjlXXrl09WZPpI0LUzsaNG/Xaa695vQw0IFOm\nTFFeXp7y8vK0fv163XvvvcrIyLjk2Vl9MR3Cc09Njh49qnHjxqlDhw7q2rWrZs2aperqav9tKyoq\nNGHCBMXGxqpHjx5av359va8vKipKK1eu1MCBAxUTE6Phw4dr//79ysjIUFxcnAYMGKCSkhL/7det\nW6fU1FTFxsaqZ8+eeuGFF3Tu/zi0aNEiJSUlKS4uTkOHDlVRUVGNeUuXLlX37t0VGxur6dOnS5JW\nrVql8ePHa+fOnYqOjlZRUZF8Pp8yMzPVu3dvtW/fXqmpqdq4cWO9/zwkaf/+/Ro9erQ6d+6sDh06\naPz48Tp27JiWL1+uxMRESf9+XtevX+//eaSlpenAgQOurLGudu7cqf79+ysuLk7p6ekqKyursR9J\nKigo0LBhw5SQkKDExEQ9+eSTOn36tCRp+fLl6tu3r+bMmaO4uLgar4nvg7CwMA0ZMkSRkZF69913\nPVmD6RCe64knnlBVVZXee+89vf7661q7dq0WLVrkv/7111/Xgw8+qE2bNqlr1656+umnXVnXkiVL\nNH/+fL311lvavn27hg0bpkceeUQffvihqqqq/GvcvXu3fvWrXykjI0NbtmzR888/r+zsbC1btkyS\ntHbtWmVlZSkzM1ObNm3Sj370I40dO9Y/p6ysTIcPH9batWuVmZmpxYsXa+vWrerXr59Gjx6tO++8\nU3l5eYqMjNSf//xnvfnmm1qwYIFyc3OVlpamMWPG6Pjx4/X6s3AcR6NHj1bz5s31zjvvKCcnR+Xl\n5frd7353wdtnZ2frxRdf1Lp163T8+HH96U9/qtf1Xa5XX31VWVlZev/99xUcHKzHH3+8xvUVFRV6\n+OGHlZCQoPXr1+uNN95Qfn6+MjMz/bf54osvFBAQoM2bN6t169Zub+GKqK6uVlCQN+/WEUJJx48f\n17vvvqtRo0apcePGuvnmm/Xss88qPj7ef5u7775bsbGxCg0NVd++ffX555/rzJkz9b62e++9Vy1b\ntlSbNm3Url073XHHHYqJidF1112nhIQE7d27V9LZUHfq1Ek//elPFRwcrLi4OKWkpOjtt9+WJC1b\ntkwpKSm68847FRISorFjx2rMmDH+PQQEBCgjI0OhoaHq1q2bbrzxRhUWFl5wTUuXLtXQoUN1yy23\nKDg4WIMHD1br1q21evXqev1Z5OXlqaCgQJMmTdK1116rG264QePGjdPq1atVUVFx3u3vv/9+tWjR\nQjfccIMSExMvuh+vpaWlqVWrVmrSpIlGjBih3Nxcff311/7r33vvPZ05c0aPPPKIQkJCFB4erl/+\n8pd64403/LcpLy/XyJEjFRwcrICAAC+2cdm+/vprLV68WPv27VOvXr08WYPpD0u+ERgYKJ/PV+Nf\n0piYmBq3Ofe6sLAwOY6jyspKBQcH1+vabrrpJv/XoaGhatmyZY3vKysrJUklJSW69dZba9y3bdu2\n/lPWkpISdezY0X/dD3/4Q6WkpPi/Dw8PV6NGjfzfh4WF+U+9/lNxcbFmzZql2bNn+y9zHEf79++/\nnC3WWklJiXw+n7p06XLedRd6Hs59zq655pqL7sdr5z5vERERchynxn5KSkp0/PhxRUdH17ifz+fz\nP//XXXedmjRp4s6Cr4CZM2f6Xz9hYWGKiorSwoUL1aZNG0/WQwgl//to3/aLeLz6V/abT9Yu9v03\nvvkP4j99s+6AgAD5fL4rsqawsDD99re/rRFSN4SGhio0NFQff/zxedctX778vMsu9rO62py7zm9e\ng4cPH/ZfFhoaqsjISP/R/YWc+4/Y98GUKVOUnp7u9TL8vh+vFBcEBgbW+PAgNze33k/1rqSIiIjz\nTv0+++wztW3bVpLUpk2bGvs7ceKEXnrpJZ08efKyZhUUFNS4rLS09DJWXTdt27bV6dOn/W8HSGff\nPzty5Ei9z65P5z4vxcXFatSokZo3b+6/rG3btiorK1N5ebn/si+//FJfffWVq+tsyAihpKZNmyo5\nOVkvvPCCjh07poMHD2ratGkqLi72emm1NmDAAG3atEk5OTmqqqpSbm6uVq1apQEDBkiSBg4cqNWr\nVys3N1eVlZXKysrSsmXLdO21117ysUNDQ/XFF1/o2LFjqqysVFpampYsWaLc3FxVV1frnXfeUb9+\n/fTZZ5/V6x7btWunjh07avr06Tp69Kj/g5Jf//rX9Tq3vi1ZskSHDh1SeXm5srOz1bNnzxqnxt26\ndVPz5s01Y8YMffXVVzp69KgmTpx40Q+JUHeE8F9mzZql66+/XklJSRo4cKC6d++uESNGeL2sWouJ\nidHMmTM1d+5cJSQkaNq0aXriiSfUt29fSVJycrImTpyoCRMmKDExUbt27arxqeO36dWrlwIDA/WT\nn/xEH3/8sQYOHKgHH3xQ48ePV3x8vObOnatnnnlGt9xyS31uUZI0Z84cBQUFKTk5WcnJyTpx4oSe\nffbZep9bn9LS0jRixAh1795dVVVVeuqpp2pcHxQUpPnz56ukpETdunVTv379dOONN+rJJ5/0ZsEN\nUAC/oRqAdRwRAjCPEAIwjxACMI8QAjCPEAIwjxACMI8QAjCPEAIwjxACMO9799tnegcOcm3Wix8/\no1Exj7ky643Sza7MkaRrmv9dFYfvcW3efZHdXJv14tZZGhU/2ZVZzpkL/8af+uDma9Ftbu4tx7f0\ngpdzRPgtIu+K8HoJ9aJRcJTXS6g3//Xf3vw+u/rWUF+L0tWxN0IIwDxCCMA8QgjAPEIIwDxCCMA8\nQgjAPEIIwDxCCMA8QgjAPEIIwDxCCMA8QgjAPEIIwDxCCMA8QgjAPEIIwDxCCMA8QgjAPEIIwDxC\nCMC8qyqEZWVlio6O1p49e7xeCgBDrqo/59mqVSvl5eV5vQwAxlxVR4QA4IWrKoSlpaWKiorS7t27\nvV4KAEOuqhACgBcCHMdxvF7EN0pLS5WcnKyVK1fqtttuu+BtivKLFXlXhMsrA9CQXVUfltTGqJjH\nXJuV41uq3oGDXJn1RulmV+ZI0nXhn6t8X1vX5t0X2c21WX8//YruCf1fV2Y5ZypdmSO5+1p0m5t7\ny/EtveDlnBoDMI8QAjCPEAIwjxACMO+q+rCkdevWKigo8HoZAIzhiBCAeYQQgHmEEIB5hBCAeYQQ\ngHmEEIB5hBCAeYQQgHmEEIB5hBCAeYQQgHmEEIB5hBCAeYQQgHmEEIB5hBCAeYQQgHmEEIB5hBCA\neYQQgHlX1R9vsmxA606uzcrxuTtPqnRxluSccWfemn3bXZnjxbw+4bGuzboacEQIwDxCCMA8QgjA\nPEIIwDxCCMA8QgjAPEIIwDxCCMA8QgjAPEIIwDxCCMA8QgjAPEIIwDxCCMA8QgjAPEIIwDxCCMA8\nQgjAPEIIwDxCCMA8QgjAPEIIwLyrJoTLly/XkSNHvF4GAIOuihBWV1dr5syZhBCAJy4Zwrvvvls5\nOTn+7x9++GGlpKT4v//kk08UHR2twsJCZWRkKDExUQkJCRo9erQOHTrkv11UVJTWrFmjtLQ0xcbG\nqn///iooKJAkdejQQSdOnNB9992n559//kruDwAu6ZIhTExM1NatWyWdPXLbsWOHTp06pWPHjkmS\ncnNzFRcXp6efflqNGzfWhx9+qHXr1qm8vFyzZ8+u8VgLFy7UjBkztGHDBjVt2lTz5s2TJK1atUrS\n2dPjcePGXdENAsClXDKEnTt31rZt2yRJO3bsUNu2bRUTE6OPPvpI0tkQdunSRQsWLND06dMVEhKi\nxo0bKykpSfn5+TUeq1+/foqMjNQPfvAD9ejRQ4WFhfWwJQCom6BL3aBz5876zW9+o9OnT2vLli3q\n2LGjWrRooY8++ki9evVSbm6uhg8frvz8fD333HP65JNPVFlZKZ/Pp5YtW9Z4rNatW/u/vuaaa3T6\n9Ok6L/jFj59R5F0Rdb7f5crxLXVtlpsa6r6khru3wJs+dW1Wjs+1Uf+a5+1zdskQ3nzzzQoPD1de\nXp62bNmiwYMHq1mzZlq1apWKi4t16tQpRUREKDk5WYMGDVJWVpaaNGmi7OxsZWdn13iswMDv/tnM\nqJjHvvNj1FaOb6l6Bw5ybZ5bGuq+JHf3tmbfdlfmSGcj6DvQzrV5fcJjXZvl5nN2seDWqkydO3dW\nbm6utm3bpvj4eN1xxx0qKirSP/7xD3Xq1El79+7VyZMn9dBDD6lJkyaSzp5GA8D3Qa1DuGLFCrVo\n0UJNmzZVUFCQbr/9dr3yyivq0qWLwsPDFRgYqG3btqmiokKvvfaaioqK9OWXX+rUqVOXfPywsDBJ\n0t69e1VeXv7ddgQAdVSrECYmJmrv3r3q0KGD/7L4+Hjt2bNHP/7xj9WyZUtNmjRJ06ZNU8+ePVVY\nWKi5c+fq+uuv1z333HPJx2/WrJn69OmjCRMmaM6cOZe/GwC4DAGO4zheL6Iu3Hxvq6G+l9ZQ9yXx\nHuGVwnuEAGAMIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAe\nIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4h\nBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEE\nYB4hBGAeIQRgHiEEYB4hBGCepyHcsWOHhgwZooSEBHXu3FmTJk1SeXm5l0sCYJCnIRw3bpzat2+v\nf/7zn1q1apXy8/P1hz/8wcslATAowHEcx6vhJ0+eVHBwsEJCQiRJ06dPV1FRkV566aWL3qcov1iR\nd0W4tUQABgR5OXzjxo2aP3++ioqKVFVVperqanXo0OFb7zMq5jGXVifl+Jaqd+Ag1+a5paHuS3J3\nb2v2bXdljiQF3vSpfAfauTavT3isa7PcfM5yfEsveLlnp8aFhYV69NFH1a9fP23YsEF5eXlKT0/3\najkADPPsiHDXrl1q1KiRhg8froCAAElnPzwJDOSDbADu8qw6bdq0UWVlpfLz81VeXq7MzExVVFTo\n8OHDqq6u9mpZAAzyLITt27fXsGHDNHz4cPXp00fBwcGaMWOGTpw4wSkyAFd5+mHJ5MmTNXny5BqX\nbdiwwaPVALCKN+QAmEcIAZhHCAGYRwgBmEcIAZhHCAGYRwgBmEcIAZhHCAGYRwgBmEcIAZhHCAGY\nRwgBmEcIAZhHCAGYRwgBmEcIAZhHCAGYRwgBmEcIAZjn6R9vuhwRm65tkPOKE0+6MscLp37WqUHO\n6xPuyhhJUo5P6hMe695AYzgiBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAe\nIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYF6tQ1haWqqoqCjt3r27\nPtcDAK7jiBCAeYQQgHl1DuHOnTvVv39/xcXFKT09XWVlZZKkzZs36xe/+IXi4+PVrVs3Pffcc/L5\nfP77/eUvf1FKSorat2+vPn366G9/+5v/uiFDhmj27NlKTU3V0KFDr8C2AKD26hzCV199VVlZWXr/\n/fcVHBysxx9/XAcOHFBGRoZ+/vOfa/PmzVq0aJFWrlypv/71r5KktWvX6ve//71mzZqlrVu3avLk\nyZo0aZIKCwv9j/vWW29p2rRpWrRo0RXbHADUilNLJSUlzm233easWLHCf9kHH3zgREVFOZmZmc6A\nAQNq3P6Pf/yjc//99zuO4zgjR450Zs2aVeP6jIwMZ86cOY7jOE56erozZsyYWq2j9GRJbZcMALUS\nVNdw3nrrrf6vIyIi5DiONm3apF27dik6OvrcwKpZs2aSpOLiYq1fv14vv/xyjesbN27s/z48PLxW\n85/c8URdl3zZXkpYpIe2DHNlVnHiSVfmSFKOb6l6Bw5ybd6pn3VybdaHb05U9//5P1dmha3c7Moc\nyf3nzE1u7i3Ht/SCl9c5hIGB/z6bdhxHktSqVSuFhIRo4cKFF7xPWFiYHn30UY0aNeqijxsUVOel\nAMAVUef3CIuKivxfFxcXq1GjRrr99tv16aef1vhw5MiRIzp16pSks0eOBQUFNR5n3759NW4PAF6p\ncwiXLFmiQ4cOqby8XNnZ2erZs6dSU1NVXl6uefPmqaKiQvv27dPIkSO1YMECSVJaWprWrFmjtWvX\nqqqqSlu3blVqaqo2bdp0xTcEAHVV5xCmpaVpxIgR6t69u6qqqvTUU0+padOmysrK0gcffKDExEQN\nHjxYCQkJGjNmjCSpS5cumjp1qmbOnKn4+HhNnTpVEydOVJcuXa74hgCgrmr9xlzr1q39p7cpKSnn\nXd+pUyctW7bsovd/4IEH9MADD1zwusWLF9d2GQBwxfF/lgAwjxACMI8QAjCPEAIwjxACMI8QAjCP\nEAIwjxACMI8QAjCPEAIwjxACMI8QAjCPEAIwjxACMI8QAjCPEAIwjxACMI8QAjCPEAIwjxACMO97\n91fVixNPujfM5/K8Bips5eYGPa8hWrNve4Oe9584IgRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRg\nHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAeIQRgHiEEYB4hBGAe\nIQRgnid/zjMpKUkHDx5UYOD5HZ46darS0tI8WBUAqzz7u8ZTpkxRenq6V+MBwI9TYwDmEUIA5nl2\najxz5kzNnj37vMu3b9+uRo0aebAiAFYFOI7juD00KSlJI0aMuKz3CIvyixV5V0Q9rAqAVZ4dEV6u\nUTGPuTYrx7dUvQMHuTbPLQ11X1LD3Zvb+1qzb7trswJv+lS+A+1cm3XBy12ZDgBXMUIIwLyr7sOS\nnj17KjMz04MVAbDKkxCuW7fOi7EAcEGcGgMwjxACMI8QAjCPEAIwjxACMI8QAjCPEAIwjxACMI8Q\nAjCPEAIwjxACMI8QAjCPEAIwjxACMI8QAjCPEAIwjxACMI8QAjCPEAIwjxACMI8QAjAvwHEcx+tF\nAICXOCIEYB4hBGAeIQRgHiEEYB4hBGAeIQRg3v8DRlYGZquxWjEAAAAASUVORK5CYII=\n","text/plain":["<Figure size 360x360 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}