{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"biLSTM-Torch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"W86UZM5GUJns","colab_type":"code","outputId":"f8c05048-7ae5-480a-a97f-e684050d44e6","executionInfo":{"status":"ok","timestamp":1550646007689,"user_tz":-540,"elapsed":18069,"user":{"displayName":"Minho Ryu","photoUrl":"https://lh5.googleusercontent.com/-DfVUFWgMLnc/AAAAAAAAAAI/AAAAAAAAApE/jyfqVt9TIvM/s64/photo.jpg","userId":"01830135931220651986"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"cell_type":"code","source":["'''\n","  code by Minho Ryu @bzantium\n","  \n","'''\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","\n","from torch import LongTensor as LT\n","\n","sentence = (\n","    'Lorem ipsum dolor sit amet consectetur adipisicing elit '\n","    'sed do eiusmod tempor incididunt ut labore et dolore magna '\n","    'aliqua Ut enim ad minim veniam quis nostrud exercitation'\n",")\n","\n","word_dict = {w: i for i, w in enumerate(list(set(sentence.split())))}\n","word_dict['<E>'] = len(word_dict)\n","number_dict = {i: w for w, i in word_dict.items()}\n","vocab_size = len(word_dict)\n","n_embed = 5\n","n_class = len(word_dict)\n","n_step = len(sentence.split())\n","n_hidden = 5\n","n_batch = 32\n","\n","def make_batch(sentence, n_batch):\n","    words = sentence.split()\n","    input_batch = []\n","    target_batch = []\n","    for _ in range(n_batch):\n","        input_batch.append([word_dict[n] for n in words])\n","        target_batch.append([word_dict[n] for n in (sentence + ' <E>').split()[1:]])\n","\n","    return LT(input_batch), LT(target_batch)\n","\n","class BiLSTM(nn.Module):\n","    def __init__(self, vocab_size, n_embed, n_hidden, n_class):\n","        super(BiLSTM, self).__init__()\n","        self.lstm = nn.LSTM(input_size=n_embed, hidden_size=n_hidden, bidirectional=True)\n","        self.embedding = nn.Embedding(vocab_size, n_embed)\n","        self.linear = nn.Linear(2*n_hidden, n_class)\n","\n","    def forward(self, X):\n","        inputs = self.embedding(X)\n","        inputs = inputs.transpose(0, 1)\n","\n","        hidden_state = Variable(torch.zeros(1*2, len(X), n_hidden))   # [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n","        cell_state = Variable(torch.zeros(1*2, len(X), n_hidden))     # [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n","\n","        outputs, (_, _) = self.lstm(inputs, (hidden_state, cell_state))\n","        outputs = outputs.transpose(0, 1)\n","        model = self.linear(outputs).transpose(1, 2)\n","        return model\n","      \n","input_batch, target_batch = make_batch(sentence, n_batch)\n","\n","model = BiLSTM(vocab_size, n_embed, n_hidden, n_class)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training\n","for epoch in range(1000):\n","    optimizer.zero_grad()\n","    \n","    output = model(input_batch)\n","    loss = criterion(output, target_batch)\n","    if (epoch + 1) % 100 == 0:\n","        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","predict = model(input_batch[0].unsqueeze(0)).data.max(1, keepdim=True)[1]\n","print(sentence)\n","print([number_dict[n.item()] for n in predict.squeeze()])"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Epoch: 0100 cost = 3.061696\n","Epoch: 0200 cost = 2.355835\n","Epoch: 0300 cost = 1.712905\n","Epoch: 0400 cost = 1.251645\n","Epoch: 0500 cost = 0.912084\n","Epoch: 0600 cost = 0.666684\n","Epoch: 0700 cost = 0.497319\n","Epoch: 0800 cost = 0.379404\n","Epoch: 0900 cost = 0.294939\n","Epoch: 1000 cost = 0.233430\n","Lorem ipsum dolor sit amet consectetur adipisicing elit sed do eiusmod tempor incididunt ut labore et dolore magna aliqua Ut enim ad minim veniam quis nostrud exercitation\n","['ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipisicing', 'elit', 'sed', 'do', 'eiusmod', 'tempor', 'incididunt', 'ut', 'labore', 'et', 'dolore', 'magna', 'aliqua', 'Ut', 'enim', 'ad', 'minim', 'veniam', 'quis', 'nostrud', 'exercitation', '<E>']\n"],"name":"stdout"}]}]}